---
title: "04_MB_Xeno_LDA_workflow"
knit: (function(input, encoding) {
  rmarkdown::render(input = input,
                    output_dir = here::here("Output", "HTML"),
                    knit_root_dir = rprojroot::find_rstudio_root_file())})
output:
  html_document: 
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document: 
    toc: yes
date: "2023-11-13"
---
```{r}
# Setup path for the root folder
# here::here("/Users/cuixinyue/Desktop/MB_Xeno_analysis")
set_here("/Users/cuixinyue/Desktop/TNBC_analysis")
# getwd()
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#knitr::opts_knit$set(root.dir = "../")
#knitr::opts_knit$set(output.dir = "../Output_Documents/")
options(dplyr.summarise.inform = FALSE)
```

```{r warning=FALSE, message=FALSE}
#library(phyloseq)
library(dplyr)
library(magrittr)
library(ggplot2)
library(stringr)
#library(genefilter) 
library(rstan)
library(randomcoloR)
library(SpatialExperiment)
#library(DESeq2)
library(here)
``` 

```{r}
theme_set(theme_minimal())
theme_update(
  text = element_text(size = 10),
  legend.text = element_text(size = 10)
)

# force not to use scientific notation
options(scipen=999)
```
## Dataset
Load the MB_Xeno SPE object.
```{r}
load(file = here::here("Output","RData","02_TNBC_spe_LC.rds"))
spe
```

## Application

We now want to apply the Latent Dirichlet Allocation to the complete dataset with 39 patients to find topics in their celluar neighbourhood.
```{r}
# Inspect complete dataset
spe
```

### Document-Term Matrix

We first want to create the document-term matrix of the dataset where the rows are the sample identity and columns are the cell types fill with counts. The expected dimension of the DTM is 9 rows by 33 columns.

```{r}
dtm <- as.data.frame.matrix(table(spe$sample_id, spe$mm)) %>% as.matrix()
dtm <- as.matrix(table(spe$sample_id, spe$mm))
dim(dtm)
dim_names <- dimnames(dtm)
col_names <- colnames(dtm)
```

```{r}
get_lda_result <- function(K, alpha, gamma, dtm, iter, chains,filefolder) {
  # setting seed will align topics
  # not applying seed, topics will differ but similar probabilities
  set.seed(19991116)
  
  K <- K
  alpha <- alpha
  gamma <- gamma
  x <- dtm
  # View(x)
  dimnames(x) <- NULL
  
  # theta[d] ~ dirichlet(alpha), alpha pseudo-count for each topic
  # beta[k] ~ dirichlet(gamma), gamma pseudo-count for each ASV in each topic
  
  # n is DTM
  stan.data <- list(
    K = K,
    V = ncol(x),
    D = nrow(x),
    n = x,
    alpha = rep(alpha, K),
    gamma = rep(gamma, ncol(x))
  )
  
  #number of iteration
  iter <- iter
  # file name
  fileN <- paste0("JABES_Endo_all_K_",
                  K,
                  "_ite_",
                  iter,
                  ".RData")
  
  # number of chains
  chains <- chains
  
  # apply dataset
  t1 <- proc.time()
  stan.fit <- stan(
    file = here::here("R_notebooks", "06_LDA_scripts", "06_lda.stan"),
    data = stan.data,
    # must be list object
    iter = iter,
    chains = chains,
    sample_file = NULL,
    diagnostic_file = NULL,
    cores = 4,
    control = list(adapt_delta = 0.9),
    save_dso = TRUE,
    algorithm = "NUTS"
  )
  proc_time <- proc.time() - t1   # processing time
  # save file with specified name
  save(stan.fit, 
       file = here::here("Output", "RData", paste0(fileN)))
  
  res <- rstan::extract(
    stan.fit,
    permuted = TRUE,
    inc_warmup = FALSE,
    include = TRUE
  )
  
  return(res)
}
```

```{r}
load_lda_file <- function(file) {
  # load lda file as stan.fit
  #load(here::here("Output", "Data", "04_MB_Xeno_LDA", paste0(fileN)))
  load(file)
  
  # extract 
  res <- rstan::extract(
    stan.fit,
    permuted = TRUE,
    inc_warmup = FALSE,
    include = TRUE
  )
  
  return(res)
}
```

```{r eval=FALSE}
sample_500 <- get_lda_result(K = 3, alpha = 0.8, gamma = 0.8,
               dtm = dtm, iter = 500, chains = 1)
sample_1000 <- get_lda_result(K = 3, alpha = 0.8, gamma = 0.8,
               dtm = dtm, iter = 1000, chains = 1)
sample_2000 <- get_lda_result(K = 3, alpha = 0.8, gamma = 0.8,
               dtm = dtm, iter = 2000, chains = 1)
```


```{r eval=TRUE}
sample_500  <- load_lda_file(
  file = here::here("Output", "RData","JABES_Endo_all_K_3_ite_500.RData") 
  )
sample_1000 <- load_lda_file(
  file = here::here("Output", "RData","JABES_Endo_all_K_3_ite_1000.RData")
  )
sample_2000 <- load_lda_file(
  file = here::here("Output", "RData","JABES_Endo_all_K_3_ite_2000.RData")
)
```

### Topics analysis

We would like to analyze the results from applying LDA to the sample dataset. Since we are interested in the parameters $\theta$ and $B = \left[\beta_{1}, \cdots, \beta_{K} \right]^{T}$, we want to extract them from the results and check their dimensions. 


#### $\theta$

We start with $\theta$. The dimension of $\theta$ is i x 9 x 3, where i is the number of iteration with 9 tissues and 3 topics. Each value is the probability of each patient in each topic in each iteration.

We want to extract estimated $\theta$ value from each iteration run for different iterations.
```{r}
theta_500 <- sample_500$theta
dim(theta_500)
theta_1000 <- sample_1000$theta
dim(theta_1000)
theta_2000 <- sample_2000$theta
dim(theta_2000)
```
We then want to set sample identity label and topic label to each iteration run, to visualize easier and extract useful information.
```{r}
topic_names <- list(paste0("Topic_", 1:3))
#tissue_names <- list(paste0("Sample_", dim_names[1]))
tissue_names <- dim_names[1] |> unlist()
dimnames(theta_500)[3] <- dimnames(theta_1000)[3] <- dimnames(theta_2000)[3] <- topic_names
dimnames(theta_500)[2] <- dimnames(theta_1000)[2] <- dimnames(theta_2000)[2] <- dim_names[1]
```
Since the results are similar from iteration 500, 1000, and 2000. We want to find the median of the topic probabilities of all sample.
```{r}
theta_topics <- sapply(1:39,
  FUN = function(k) {
    apply(data.frame(theta_2000[, k, ]), 2, mean) # |> round(6)
  }
) |> t() |> as.data.frame()

rownames(theta_topics) <- tissue_names
theta_topics$Topic <- colnames(theta_topics)[apply(theta_topics, 1, which.max)]
#knitr::kable(theta_topics, align = "c")
formattable::formattable(theta_topics, align = "c")
```


We are now interest what cell types are in each topics, thus we want to preform analysis with $\beta$ estimation. The expected dimension is i x 3 x 33, where $i$ is the number of iteration for 3 topics and 33 cell types. Each value is the probability of each cell type in each topic in each iterations.
```{r}
beta_500 <- sample_500$beta
dim(beta_500)
beta_1000 <- sample_1000$beta
dim(beta_1000)
beta_2000 <- sample_2000$beta
dim(beta_2000)
```
We want to set name of the cell types to the beta estimation to ensure the correctness of our conclusion.
```{r}
dimnames(beta_500)[3] <- dimnames(beta_1000)[3] <- dimnames(beta_2000)[3] <- list(col_names)
```

Since the estimation are similar between 500, 1000, and 2000 times of iteration, we want to use 2000 iterations estimated result. We want to find the median of the estimated results, and sort them with descending order for easier visulization.
```{r}
apply(data.frame(beta_500[, 1, ]), 2, mean) %>% sort(decreasing = TRUE)

apply(data.frame(beta_1000[, 1, ]), 2, mean) %>% sort(decreasing = TRUE)

apply(data.frame(beta_2000[, 1, ]), 2, mean) %>% sort(decreasing = TRUE)
```
```{r}
# topic 1
print("---Topic 1---")
apply(data.frame(beta_2000[, 1, ]), 2, median) %>% sort(decreasing = TRUE)
# topic 2
print("---Topic 2---")
apply(data.frame(beta_2000[, 2, ]), 2, median) %>% sort(decreasing = TRUE)
# topic 3
print("---Topic 3---")
apply(data.frame(beta_2000[, 3, ]), 2, median) %>% sort(decreasing = TRUE)
```
